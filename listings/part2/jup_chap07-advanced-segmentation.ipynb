{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "from churnmodels.schema import get_db_uri\n",
    "\n",
    "options = {\n",
    "        \"dialect\":\"sqlite\",\n",
    "        \"file\":\"../churn.db\"\n",
    "    }\n",
    "\n",
    "if True:\n",
    "    # connect to the database\n",
    "    db_uri=get_db_uri(options, \"sqlite\") # \"postgres\" names the dialect we are using\n",
    "    engine=create_engine(db_uri)\n",
    "    session = sessionmaker(bind=engine)()\n",
    "\n",
    "    # we get the log function from an extension library for sqlite\n",
    "    from sqlalchemy import event\n",
    "    @event.listens_for(engine, \"connect\")\n",
    "    def connect(dbapi_connection, connection_rec):\n",
    "        dbapi_connection.enable_load_extension(True)\n",
    "        dbapi_connection.execute('SELECT load_extension(\"libsqlitefunctions\")')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PostGres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "from churnmodels.schema import get_db_uri\n",
    "\n",
    "options = {\n",
    "        \"dialect\":\"postgresql\",\n",
    "        \"user\": \"postgres\",\n",
    "           \"pass\": \"password\",\n",
    "           \"dbname\": \"churn\",\n",
    "           \"schema\": \"biznet1\"\n",
    "           #\"host\" : \"localhost\" # ...if needed\n",
    "           #\"port\" : \"5432\" # ...if needed\n",
    "           }\n",
    "\n",
    "if True:\n",
    "    # connect to the database\n",
    "    db_uri=get_db_uri(options, \"postgres\") # \"postgres\" names the dialect we are using\n",
    "    engine=create_engine(db_uri)\n",
    "    engine.dialect.has_schema(engine, options[\"schema\"]) \n",
    "    session = sessionmaker(bind=engine)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sqlalchemy import func, or_\n",
    "import pandas as pd\n",
    "from churnmodels import DBHelper\n",
    "from churnmodels.helpers import days_between, pretty_sql\n",
    "from churnmodels.schema import get_schema_rfl\n",
    "\n",
    "#d_start_date = \"2020-01-01\"\n",
    "#d_end_date = \"2020-03-01\"\n",
    "\n",
    "d_start_date = \"2020-03-01\"\n",
    "d_end_date = \"2020-04-01\"\n",
    "\n",
    "metric_period=7\n",
    "d_obs_start = \"2020-02-09\"\n",
    "d_obs_end = \"2020-05-10\"\n",
    "\n",
    "# tables is a (dynamical) module containg Wrapper classes for our data base\n",
    "T=get_schema_rfl(options)\n",
    "# ..how to bring all tables in T to the global namespace\n",
    "for tbl in T.__dict__.keys():\n",
    "    if not tbl[0].isupper():\n",
    "        continue\n",
    "    exec(f\"{tbl} = T.{tbl}\")\n",
    "\n",
    "dbhelper=DBHelper(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func\n",
    "if session.bind.dialect.name == \"sqlite\":\n",
    "    # sqlite problematic when computing days\n",
    "    to_days = lambda some_date: func.julianday(some_date)\n",
    "else:\n",
    "    # dummy func because of sqlite\n",
    "    to_days = lambda some_date: func.DATE(some_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratio metric (§7.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>metric_name_id</th>\n",
       "      <th>metric_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>post_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>newfriend_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>like_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>adview_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>dislike_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>unfriend_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>message_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>reply_per_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>account_tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>adview_per_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>reply_per_message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>like_per_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>post_per_message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>unfriend_per_newfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>unfriend_per_newfriend_scaled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>dislike_pcnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>newfriend_pcnt_chng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>unfriend_28day_avg_84day_obs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>unfriend_28day_avg_84day_obs_scaled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>days_since_newfriend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  metric_name_id                          metric_name\n",
       "0    1               1                       post_per_month\n",
       "1    2               2                  newfriend_per_month\n",
       "2    3               3                       like_per_month\n",
       "3    4               4                     adview_per_month\n",
       "4    5               5                    dislike_per_month\n",
       "5    6               6                   unfriend_per_month\n",
       "6    7               7                    message_per_month\n",
       "7    8               8                      reply_per_month\n",
       "8    9               9                       account_tenure\n",
       "9   10              10                      adview_per_post\n",
       "10  11              11                    reply_per_message\n",
       "11  12              12                        like_per_post\n",
       "12  13              13                     post_per_message\n",
       "13  14              14               unfriend_per_newfriend\n",
       "14  15              15        unfriend_per_newfriend_scaled\n",
       "15  16              16                         dislike_pcnt\n",
       "16  17              17                  newfriend_pcnt_chng\n",
       "17  18              18         unfriend_28day_avg_84day_obs\n",
       "18  19              19  unfriend_28day_avg_84day_obs_scaled\n",
       "19  20              20                 days_since_newfriend"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual list of metric names\n",
    "pd.read_sql(session.query(MetricName).statement, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new metric\n",
    "\n",
    "# this step should be exercised before §3.3 to have a new metric id when inserting to the Metric Table\n",
    "\"\"\"\n",
    "insert into metric_name values (%new_metric_id,'%new_metric_name')\n",
    "\"\"\"\n",
    "from sqlalchemy import func\n",
    "max_id=9\n",
    "new_metrics=[\n",
    "    \"adview_per_post\",\n",
    "    \"reply_per_message\",\n",
    "    \"like_per_post\",\n",
    "    \"post_per_message\",\n",
    "    \"unfriend_per_newfriend\",\n",
    "    \n",
    "    \"unfriend_per_newfriend_scaled\",\n",
    "    \"dislike_pcnt\",\n",
    "    \"newfriend_pcnt_chng\",\n",
    "    \"unfriend_28day_avg_84day_obs\",\n",
    "    \"unfriend_28day_avg_84day_obs_scaled\",\n",
    "    \"days_since_newfriend\",\n",
    "    ]\n",
    "\n",
    "# we simply delete old metrics\n",
    "new_metric_id=max_id\n",
    "old_metrics=MetricName.__table__.delete().where(MetricName.metric_name_id>new_metric_id)\n",
    "session.execute(old_metrics)\n",
    "\n",
    "# ... and add the new ones\n",
    "max_id=session.query(func.max(MetricName.metric_name_id)).one()[0] or 0\n",
    "for metric_name in new_metrics:\n",
    "    max_id+=1\n",
    "    session.execute(MetricName.__table__.insert(), {\"metric_name\": metric_name, \"metric_name_id\":max_id})\n",
    "\n",
    "session.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can omit these routine by usiong its implementation from DBHelper...\n",
    "from sqlalchemy import func, and_, case, literal\n",
    "\n",
    "d_obs_start = \"2020-03-01\"\n",
    "d_obs_end = \"2020-05-10\"\n",
    "obs_start=to_days(func.DATE(d_obs_start))\n",
    "obs_end=to_days(func.DATE(d_obs_end))\n",
    "\n",
    "def make_relative_metrics_part(d_obs_start, d_obs_end, cte_name, target_field, metric_name):\n",
    "    num_metric=session.query(\n",
    "            Metric.account_id, \n",
    "            Metric.metric_time, \n",
    "            Metric.metric_value.label(target_field)\n",
    "            )\\\n",
    "        .join(MetricName, Metric.metric_name_id==MetricName.metric_name_id)\\\n",
    "        .filter(MetricName.metric_name == metric_name,\n",
    "            Metric.metric_time.between(d_obs_start, d_obs_end)\n",
    "           )\\\n",
    "        .order_by(Metric.account_id, Metric.metric_time)\\\n",
    "        .cte(cte_name)\n",
    "    return num_metric\n",
    "\n",
    "def make_relative_metrics_sub(num_metric, den_metric, metric_name_lu=-1):\n",
    "    qr=session.query(\n",
    "            num_metric.c.account_id,\n",
    "            func.DATE(num_metric.c.metric_time),\n",
    "            literal(metric_name_lu).label(\"metric_name_id\"),\n",
    "            case([\n",
    "                (num_metric.c.num_value == None, 0),\n",
    "                (den_metric.c.den_value == None, 0),\n",
    "                (den_metric.c.den_value == 0, 0),\n",
    "                (den_metric.c.den_value != 0, num_metric.c.num_value/den_metric.c.den_value)\n",
    "            ], else_=0). label(\"metric_value\"),\n",
    "            case([\n",
    "                (num_metric.c.num_value == None, 0),\n",
    "                (den_metric.c.den_value == None, 0),\n",
    "                (den_metric.c.den_value == 0, 0),\n",
    "                (num_metric.c.num_value/den_metric.c.den_value > 0, func.log(num_metric.c.num_value/den_metric.c.den_value))\n",
    "            ], else_=0). label(\"metric_value_log\")\n",
    "            )\\\n",
    "        .join(den_metric, and_(\n",
    "            num_metric.c.account_id==den_metric.c.account_id,\n",
    "            num_metric.c.metric_time==den_metric.c.metric_time\n",
    "        ), isouter=True)\\\n",
    "        .order_by(num_metric.c.account_id, num_metric.c.metric_time)\\\n",
    "    \n",
    "    return qr\n",
    "\n",
    "num_metric = make_relative_metrics_part(d_obs_start, d_obs_end, \"num_metric\", \"num_value\", \"like_per_month\")\n",
    "den_metric = make_relative_metrics_part(d_obs_start, d_obs_end, \"den_metric\", \"den_value\", \"dislike_per_month\")\n",
    "qr = make_relative_metrics_sub(num_metric, den_metric)\n",
    "#print(qr.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               1  2020-03-01              -1     21.000000          3.044522\n",
      "1               1  2020-03-08              -1     21.500000          3.068053\n",
      "2               1  2020-03-15              -1     23.500000          3.157000\n",
      "3               1  2020-03-22              -1     29.000000          3.367296\n",
      "4               1  2020-03-29              -1     61.000000          4.110874\n",
      "...           ...         ...             ...           ...               ...\n",
      "54373       12098  2020-03-29              -1      5.750000          1.749200\n",
      "54374       12099  2020-03-22              -1     22.750000          3.124565\n",
      "54375       12099  2020-03-29              -1     25.428571          3.235873\n",
      "54376       12100  2020-03-22              -1     66.000000          4.189655\n",
      "54377       12100  2020-03-29              -1     86.333333          4.458216\n",
      "\n",
      "[54378 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "qr=dbhelper.make_relative_metrics(d_obs_start, d_obs_end, \"like_per_month\", \"dislike_per_month\")\n",
    "ddf=pd.read_sql(qr.statement, engine)\n",
    "print(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new metric_name_id=-1 for like_per_dislike\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               1  2020-03-01              -1     21.000000          3.044522\n",
      "1               1  2020-03-08              -1     21.500000          3.068053\n",
      "2               1  2020-03-15              -1     23.500000          3.157000\n",
      "3               1  2020-03-22              -1     29.000000          3.367296\n",
      "4               1  2020-03-29              -1     61.000000          4.110874\n",
      "...           ...         ...             ...           ...               ...\n",
      "54373       12098  2020-03-29              -1      5.750000          1.749200\n",
      "54374       12099  2020-03-22              -1     22.750000          3.124565\n",
      "54375       12099  2020-03-29              -1     25.428571          3.235873\n",
      "54376       12100  2020-03-22              -1     66.000000          4.189655\n",
      "54377       12100  2020-03-29              -1     86.333333          4.458216\n",
      "\n",
      "[54378 rows x 5 columns]\n",
      "new metric_name_id=10 for adview_per_post\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               1  2020-03-01              -1      2.666667          0.980829\n",
      "1               1  2020-03-08              -1      2.250000          0.810930\n",
      "2               1  2020-03-15              -1      1.000000          0.000000\n",
      "3               1  2020-03-22              -1      1.600000          0.470004\n",
      "4               1  2020-03-29              -1      2.666667          0.980829\n",
      "...           ...         ...             ...           ...               ...\n",
      "53652       12098  2020-03-29              -1      3.500000          1.252763\n",
      "53653       12099  2020-03-22              -1      2.000000          0.693147\n",
      "53654       12099  2020-03-29              -1      1.653061          0.502629\n",
      "53655       12100  2020-03-22              -1      0.473684         -0.747214\n",
      "53656       12100  2020-03-29              -1      0.365248         -1.007178\n",
      "\n",
      "[53657 rows x 5 columns]\n",
      "new metric_name_id=11 for reply_per_message\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               1  2020-03-01              -1      1.000000          0.000000\n",
      "1               1  2020-03-08              -1      1.000000          0.000000\n",
      "2               1  2020-03-15              -1      1.666667          0.510826\n",
      "3               1  2020-03-22              -1      0.800000         -0.223144\n",
      "4               1  2020-03-29              -1      0.700000         -0.356675\n",
      "...           ...         ...             ...           ...               ...\n",
      "48537       12098  2020-03-29              -1      0.518519         -0.656780\n",
      "48538       12099  2020-03-22              -1      0.400000         -0.916291\n",
      "48539       12099  2020-03-29              -1      0.555556         -0.587787\n",
      "48540       12100  2020-03-22              -1      0.333333         -1.098612\n",
      "48541       12100  2020-03-29              -1      0.200000         -1.609438\n",
      "\n",
      "[48542 rows x 5 columns]\n",
      "new metric_name_id=12 for like_per_post\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               1  2020-03-01              -1     14.000000          2.639057\n",
      "1               1  2020-03-08              -1     10.750000          2.374906\n",
      "2               1  2020-03-15              -1     11.750000          2.463853\n",
      "3               1  2020-03-22              -1     11.600000          2.451005\n",
      "4               1  2020-03-29              -1     20.333333          3.012262\n",
      "...           ...         ...             ...           ...               ...\n",
      "54373       12098  2020-03-29              -1      3.833333          1.343735\n",
      "54374       12099  2020-03-22              -1      4.550000          1.515127\n",
      "54375       12099  2020-03-29              -1      3.632653          1.289963\n",
      "54376       12100  2020-03-22              -1      1.157895          0.146603\n",
      "54377       12100  2020-03-29              -1      0.918440         -0.085079\n",
      "\n",
      "[54378 rows x 5 columns]\n",
      "new metric_name_id=13 for post_per_message\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               1  2020-03-01              -1      0.300000         -1.203973\n",
      "1               1  2020-03-08              -1      0.444444         -0.810930\n",
      "2               1  2020-03-15              -1      0.666667         -0.405465\n",
      "3               1  2020-03-22              -1      0.500000         -0.693147\n",
      "4               1  2020-03-29              -1      0.300000         -1.203973\n",
      "...           ...         ...             ...           ...               ...\n",
      "53568       12098  2020-03-29              -1      0.222222         -1.504077\n",
      "53569       12099  2020-03-22              -1      2.000000          0.693147\n",
      "53570       12099  2020-03-29              -1      2.722222          1.001449\n",
      "53571       12100  2020-03-22              -1     38.000000          3.637586\n",
      "53572       12100  2020-03-29              -1     56.400000          4.032469\n",
      "\n",
      "[53573 rows x 5 columns]\n",
      "new metric_name_id=14 for unfriend_per_newfriend\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               2  2020-03-01              -1      0.250000         -1.386294\n",
      "1               2  2020-03-08              -1      0.250000         -1.386294\n",
      "2               2  2020-03-15              -1      0.250000         -1.386294\n",
      "3               2  2020-03-22              -1      0.666667         -0.405465\n",
      "4               4  2020-03-01              -1      0.200000         -1.609438\n",
      "...           ...         ...             ...           ...               ...\n",
      "31550       12095  2020-03-22              -1      0.071429         -2.639057\n",
      "31551       12095  2020-03-29              -1      0.041667         -3.178054\n",
      "31552       12097  2020-03-22              -1      0.500000         -0.693147\n",
      "31553       12097  2020-03-29              -1      0.500000         -0.693147\n",
      "31554       12099  2020-03-29              -1      0.076923         -2.564949\n",
      "\n",
      "[31555 rows x 5 columns]\n",
      "new metric_name_id=15 for unfriend_per_newfriend_scaled\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               2  2020-03-01              -1      0.152174         -1.882731\n",
      "1               2  2020-03-08              -1      0.132075         -2.024382\n",
      "2               4  2020-03-01              -1      0.476596         -0.741087\n",
      "3               4  2020-03-08              -1      0.345679         -1.062245\n",
      "4               4  2020-03-15              -1      0.306011         -1.184134\n",
      "...           ...         ...             ...           ...               ...\n",
      "40175       12088  2020-03-29              -1      0.181818         -1.704748\n",
      "40176       12092  2020-03-29              -1      1.400000          0.336472\n",
      "40177       12093  2020-03-22              -1      0.491228         -0.710847\n",
      "40178       12093  2020-03-29              -1      0.461538         -0.773190\n",
      "40179       12095  2020-03-29              -1      0.055556         -2.890372\n",
      "\n",
      "[40180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "todo={\n",
    "     \"like_per_dislike\":[\"like_per_month\", \"dislike_per_month\"],\n",
    "     \"adview_per_post\":[\"adview_per_month\", \"post_per_month\"],\n",
    "    \"reply_per_message\":[\"reply_per_month\", \"message_per_month\"],\n",
    "    \"like_per_post\":[\"like_per_month\", \"post_per_month\"],\n",
    "    \"post_per_message\":[\"post_per_month\", \"message_per_month\"],\n",
    "    \"unfriend_per_newfriend\":[\"unfriend_per_month\", \"newfriend_per_month\"],\n",
    "    \n",
    "    # run this step later...\n",
    "    #\"unfriend_per_newfriend_scaled\":[\"unfriend_28day_avg_84day_obs_scaled\", \"newfriend_per_month\"],\n",
    "}\n",
    "\n",
    "for newmetricname, pairs in todo.items():\n",
    "    metric_name_id=-1\n",
    "    metric_name_lu=session.query(MetricName.metric_name_id)\\\n",
    "        .filter(MetricName.metric_name == newmetricname).first() #or 0\n",
    "    if metric_name_lu is not None:\n",
    "        metric_name_lu = metric_name_lu[0]\n",
    "        metric_name_id = metric_name_lu\n",
    "    print(f\"new metric_name_id={metric_name_id} for {newmetricname}\")\n",
    "    #num_metric=make_relative_metrics_part(d_obs_start, d_obs_end, \"num_metric\", \"num_value\", pairs[0])\n",
    "    #den_metric=make_relative_metrics_part(d_obs_start, d_obs_end, \"den_metric\", \"den_value\", pairs[1])\n",
    "    #qr=qr=make_relative_metrics_sub(num_metric, den_metric, metric_name_id)\n",
    "    qr=dbhelper.make_relative_metrics(d_obs_start, d_obs_end, pairs[0], pairs[1])\n",
    "    #print(pretty_sql(qr))\n",
    "    ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "    print(ddf)\n",
    "    \n",
    "    if metric_name_id>0:\n",
    "        # delete all old values \"new_metric_id\"\n",
    "        session.commit()\n",
    "        old_metrics=session.query(Metric).filter(Metric.metric_name_id==metric_name_id).filter(Metric.metric_name_id==-1)\n",
    "        old_metrics.delete()\n",
    "        session.commit()\n",
    "        \n",
    "        new_metrics_insert=qr.cte(\"new_metrics_insert\")\n",
    "        select_stm=select([\n",
    "            new_metrics_insert.c.account_id, \n",
    "            func.DATE(new_metrics_insert.c.metric_time).label(\"metric_time\"), \n",
    "            literal(metric_name_id).label(\"metric_name_id\"), #new_metrics_insert.c.metric_name_id, \n",
    "            new_metrics_insert.c.metric_value\n",
    "        ])\n",
    "        target_columns=['account_id', 'metric_time', 'metric_name_id', 'metric_value']\n",
    "        session.execute(Metric.__table__.insert().from_select(target_columns, select_stm))\n",
    "        session.commit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting metric datasets (§7.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             is_churn  post_per_month  newfriend_per_month  \\\n",
      "account_id observation_date                                                  \n",
      "16         2020-03-01           False             8.0                  1.0   \n",
      "24         2020-03-01           False            23.0                  8.0   \n",
      "118        2020-03-01           False            13.0                  3.0   \n",
      "144        2020-03-01           False            55.0                 15.0   \n",
      "157        2020-03-01           False             0.0                  0.0   \n",
      "...                               ...             ...                  ...   \n",
      "13181      2020-05-10           False             0.0                  0.0   \n",
      "13205      2020-05-10           False             0.0                  0.0   \n",
      "13217      2020-05-10           False             0.0                  0.0   \n",
      "13280      2020-05-10           False             0.0                  0.0   \n",
      "13310      2020-05-10           False             0.0                  0.0   \n",
      "\n",
      "                             like_per_month  adview_per_month  \\\n",
      "account_id observation_date                                     \n",
      "16         2020-03-01                  34.0               4.0   \n",
      "24         2020-03-01                  39.0              12.0   \n",
      "118        2020-03-01                  10.0               7.0   \n",
      "144        2020-03-01                  41.0              30.0   \n",
      "157        2020-03-01                   1.0               0.0   \n",
      "...                                     ...               ...   \n",
      "13181      2020-05-10                   0.0               0.0   \n",
      "13205      2020-05-10                   0.0               0.0   \n",
      "13217      2020-05-10                   0.0               0.0   \n",
      "13280      2020-05-10                   0.0               0.0   \n",
      "13310      2020-05-10                   0.0               0.0   \n",
      "\n",
      "                             dislike_per_month  unfriend_per_month  \\\n",
      "account_id observation_date                                          \n",
      "16         2020-03-01                      5.0                 0.0   \n",
      "24         2020-03-01                      0.0                 0.0   \n",
      "118        2020-03-01                     15.0                 0.0   \n",
      "144        2020-03-01                     19.0                 1.0   \n",
      "157        2020-03-01                      1.0                 2.0   \n",
      "...                                        ...                 ...   \n",
      "13181      2020-05-10                      0.0                 0.0   \n",
      "13205      2020-05-10                      0.0                 0.0   \n",
      "13217      2020-05-10                      0.0                 0.0   \n",
      "13280      2020-05-10                      0.0                 0.0   \n",
      "13310      2020-05-10                      0.0                 0.0   \n",
      "\n",
      "                             message_per_month  reply_per_month  \\\n",
      "account_id observation_date                                       \n",
      "16         2020-03-01                     31.0             19.0   \n",
      "24         2020-03-01                     15.0              1.0   \n",
      "118        2020-03-01                      2.0              0.0   \n",
      "144        2020-03-01                     10.0             10.0   \n",
      "157        2020-03-01                     71.0             22.0   \n",
      "...                                        ...              ...   \n",
      "13181      2020-05-10                      0.0              0.0   \n",
      "13205      2020-05-10                      0.0              0.0   \n",
      "13217      2020-05-10                      0.0              0.0   \n",
      "13280      2020-05-10                      0.0              0.0   \n",
      "13310      2020-05-10                      0.0              0.0   \n",
      "\n",
      "                             account_tenure  ...  reply_per_message  \\\n",
      "account_id observation_date                  ...                      \n",
      "16         2020-03-01                  49.0  ...           1.838710   \n",
      "24         2020-03-01                  49.0  ...           0.200000   \n",
      "118        2020-03-01                  49.0  ...           0.000000   \n",
      "144        2020-03-01                  49.0  ...           3.000000   \n",
      "157        2020-03-01                  49.0  ...           0.929577   \n",
      "...                                     ...  ...                ...   \n",
      "13181      2020-05-10                   0.0  ...           0.000000   \n",
      "13205      2020-05-10                   0.0  ...           0.000000   \n",
      "13217      2020-05-10                   0.0  ...           0.000000   \n",
      "13280      2020-05-10                   0.0  ...           0.000000   \n",
      "13310      2020-05-10                   0.0  ...           0.000000   \n",
      "\n",
      "                             like_per_post  post_per_message  \\\n",
      "account_id observation_date                                    \n",
      "16         2020-03-01            12.750000          0.774194   \n",
      "24         2020-03-01             5.086957          4.600000   \n",
      "118        2020-03-01             2.307692         19.500000   \n",
      "144        2020-03-01             2.236364         16.500000   \n",
      "157        2020-03-01             0.000000          0.000000   \n",
      "...                                    ...               ...   \n",
      "13181      2020-05-10             0.000000          0.000000   \n",
      "13205      2020-05-10             0.000000          0.000000   \n",
      "13217      2020-05-10             0.000000          0.000000   \n",
      "13280      2020-05-10             0.000000          0.000000   \n",
      "13310      2020-05-10             0.000000          0.000000   \n",
      "\n",
      "                             unfriend_per_newfriend  \\\n",
      "account_id observation_date                           \n",
      "16         2020-03-01                           0.0   \n",
      "24         2020-03-01                           0.0   \n",
      "118        2020-03-01                           0.0   \n",
      "144        2020-03-01                           0.2   \n",
      "157        2020-03-01                           0.0   \n",
      "...                                             ...   \n",
      "13181      2020-05-10                           0.0   \n",
      "13205      2020-05-10                           0.0   \n",
      "13217      2020-05-10                           0.0   \n",
      "13280      2020-05-10                           0.0   \n",
      "13310      2020-05-10                           0.0   \n",
      "\n",
      "                             unfriend_per_newfriend_scaled  dislike_pcnt  \\\n",
      "account_id observation_date                                                \n",
      "16         2020-03-01                                    0           0.0   \n",
      "24         2020-03-01                                    0           0.0   \n",
      "118        2020-03-01                                    0           0.0   \n",
      "144        2020-03-01                                    0           0.0   \n",
      "157        2020-03-01                                    0           0.0   \n",
      "...                                                    ...           ...   \n",
      "13181      2020-05-10                                    0           0.0   \n",
      "13205      2020-05-10                                    0           0.0   \n",
      "13217      2020-05-10                                    0           0.0   \n",
      "13280      2020-05-10                                    0           0.0   \n",
      "13310      2020-05-10                                    0           0.0   \n",
      "\n",
      "                             newfriend_pcnt_chng  \\\n",
      "account_id observation_date                        \n",
      "16         2020-03-01                        0.0   \n",
      "24         2020-03-01                        0.0   \n",
      "118        2020-03-01                        0.0   \n",
      "144        2020-03-01                        0.0   \n",
      "157        2020-03-01                        0.0   \n",
      "...                                          ...   \n",
      "13181      2020-05-10                        0.0   \n",
      "13205      2020-05-10                        0.0   \n",
      "13217      2020-05-10                        0.0   \n",
      "13280      2020-05-10                        0.0   \n",
      "13310      2020-05-10                        0.0   \n",
      "\n",
      "                             unfriend_28day_avg_84day_obs  \\\n",
      "account_id observation_date                                 \n",
      "16         2020-03-01                            0.000000   \n",
      "24         2020-03-01                            0.000000   \n",
      "118        2020-03-01                            0.000000   \n",
      "144        2020-03-01                            0.000000   \n",
      "157        2020-03-01                            0.000000   \n",
      "...                                                   ...   \n",
      "13181      2020-05-10                            0.000000   \n",
      "13205      2020-05-10                            0.333333   \n",
      "13217      2020-05-10                            0.333333   \n",
      "13280      2020-05-10                            0.000000   \n",
      "13310      2020-05-10                            0.333333   \n",
      "\n",
      "                             unfriend_28day_avg_84day_obs_scaled  \\\n",
      "account_id observation_date                                        \n",
      "16         2020-03-01                                          0   \n",
      "24         2020-03-01                                          0   \n",
      "118        2020-03-01                                          0   \n",
      "144        2020-03-01                                          0   \n",
      "157        2020-03-01                                          0   \n",
      "...                                                          ...   \n",
      "13181      2020-05-10                                          0   \n",
      "13205      2020-05-10                                          0   \n",
      "13217      2020-05-10                                          0   \n",
      "13280      2020-05-10                                          0   \n",
      "13310      2020-05-10                                          0   \n",
      "\n",
      "                             days_since_newfriend  \n",
      "account_id observation_date                        \n",
      "16         2020-03-01                         0.0  \n",
      "24         2020-03-01                         0.0  \n",
      "118        2020-03-01                         0.0  \n",
      "144        2020-03-01                         0.0  \n",
      "157        2020-03-01                         0.0  \n",
      "...                                           ...  \n",
      "13181      2020-05-10                        24.0  \n",
      "13205      2020-05-10                         0.0  \n",
      "13217      2020-05-10                         4.0  \n",
      "13280      2020-05-10                         0.0  \n",
      "13310      2020-05-10                         0.0  \n",
      "\n",
      "[15561 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import case, func, literal\n",
    "import numpy as np\n",
    "\n",
    "# same as before\n",
    "def get_dataset(d_obs_start, d_end_end, metric_period):\n",
    "    fields=[\n",
    "        Metric.account_id,\n",
    "        Observation.observation_date,\n",
    "        Observation.is_churn\n",
    "    ]\n",
    "    targets={}\n",
    "    df_metricnames=pd.read_sql(session.query(MetricName).statement,engine)\n",
    "    for index, row in df_metricnames.iterrows():\n",
    "        newfield=func.sum(case([\n",
    "            (Metric.metric_name_id == row.metric_name_id, Metric.metric_value)\n",
    "            ], else_=0)).label(row.metric_name)\n",
    "        fields.append(newfield)\n",
    "\n",
    "    qr=session.query(*fields)\\\n",
    "        .join(Observation, Metric.account_id==Observation.account_id)\\\n",
    "        .filter(\n",
    "            Metric.metric_time> func.DATE(to_days(Observation.observation_date)-metric_period), \n",
    "            Metric.metric_time<= Observation.observation_date)\\\n",
    "        .group_by(Metric.account_id, Metric.metric_time,\n",
    "                  Observation.observation_date, Observation.is_churn)\\\n",
    "        .order_by(Observation.observation_date, Metric.account_id)\n",
    "\n",
    "    #print(pretty_sql(qr))\n",
    "    ddf=pd.read_sql(qr.statement, engine)\n",
    "    #ddf=ddf.set_index(\"account_id\")\n",
    "    ddf=ddf.set_index([\"account_id\", \"observation_date\"])\n",
    "    \n",
    "    return ddf\n",
    "\n",
    "dataset=dbhelper.get_dataset(d_obs_start, d_obs_end, metric_period)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total metrics (§7.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id metric_time  metric_total\n",
      "0               1  2020-03-01          44.0\n",
      "1               1  2020-03-08          45.0\n",
      "2               1  2020-03-15          49.0\n",
      "3               1  2020-03-22          60.0\n",
      "4               1  2020-03-29          62.0\n",
      "...           ...         ...           ...\n",
      "54920       12098  2020-03-29          27.0\n",
      "54921       12099  2020-03-22          95.0\n",
      "54922       12099  2020-03-29         185.0\n",
      "54923       12100  2020-03-22         134.0\n",
      "54924       12100  2020-03-29         262.0\n",
      "\n",
      "[54925 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metric_pairs=['like_per_month', 'dislike_per_month']\n",
    "\n",
    "q_total_metric=session.query(\n",
    "        Metric.account_id,\n",
    "        func.DATE(Metric.metric_time).label(\"metric_time\"),\n",
    "        func.sum(Metric.metric_value).label(\"metric_total\"),\n",
    "        )\\\n",
    "    .join(MetricName, MetricName.metric_name_id==Metric.metric_name_id)\\\n",
    "    .filter(MetricName.metric_name.in_(metric_pairs))\\\n",
    "    .group_by(Metric.account_id, Metric.metric_time)\n",
    "\n",
    "total_metric=pd.read_sql(q_total_metric.statement, engine)\n",
    "print(total_metric)\n",
    "\n",
    "#print(pretty_sql(q_total_metric))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relative changes of metric (§7.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH RECURSIVE cnt(date) AS\n",
      "  (SELECT DATE('2020-02-02') AS date\n",
      "   UNION ALL SELECT DATE(julianday(cnt.date) + 7) AS date\n",
      "   FROM cnt\n",
      "   WHERE DATE(julianday(cnt.date) + 7) <= Date(julianday('2020-05-10') - 28))\n",
      "SELECT anon_1.date AS start_date,\n",
      "       DATE(julianday(anon_1.date) + 28) AS end_date\n",
      "FROM\n",
      "  (SELECT cnt.date AS date\n",
      "   FROM cnt) AS anon_1\n",
      "    start_date    end_date\n",
      "0   2020-02-02  2020-03-01\n",
      "1   2020-02-09  2020-03-08\n",
      "2   2020-02-16  2020-03-15\n",
      "3   2020-02-23  2020-03-22\n",
      "4   2020-03-01  2020-03-29\n",
      "5   2020-03-08  2020-04-05\n",
      "6   2020-03-15  2020-04-12\n",
      "7   2020-03-22  2020-04-19\n",
      "8   2020-03-29  2020-04-26\n",
      "9   2020-04-05  2020-05-03\n",
      "10  2020-04-12  2020-05-10\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select, literal, union_all\n",
    "from datetime import timedelta\n",
    "\n",
    "# additional function to have two column table with start and end dates\n",
    "# ... it's a copy from §3\n",
    "def days_interval(d_start_date, d_end_date, step=7, label=\"date\"):\n",
    "    cnt = session.query(func.DATE(d_start_date).label(label))\\\n",
    "       .cte(name=\"cnt\", recursive=True)\n",
    "    next_date=func.DATE(to_days(cnt.c[label])+(step)).label(label)\n",
    "    end_crit=next_date <= d_end_date\n",
    "    if step<0:\n",
    "        end_crit=next_date >= d_end_date\n",
    "    union_all = cnt.union_all(select([next_date], cnt).where(end_crit))\n",
    "    return session.query(union_all)\n",
    "    #return union_all\n",
    "\n",
    "some_start='2020-02-02'\n",
    "some_end='2020-05-10'\n",
    "step=7\n",
    "\n",
    "subq=days_interval(some_start, func.Date(to_days(some_end) - 28), step=step, label=\"date\").subquery()\n",
    "q1=session.query(\n",
    "    subq.c.date.label(\"start_date\"),\n",
    "    func.DATE(to_days(subq.c.date)+28).label(\"end_date\")\n",
    "    )\n",
    "df=pd.read_sql(q1.statement, engine)\n",
    "print(pretty_sql(engine, q1))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id metric_time     metric_name  end_value\n",
      "0               1  2020-03-01  post_per_month        3.0\n",
      "1               1  2020-03-08  post_per_month        4.0\n",
      "2               1  2020-03-15  post_per_month        4.0\n",
      "3               1  2020-03-22  post_per_month        5.0\n",
      "4               1  2020-03-29  post_per_month        3.0\n",
      "...           ...         ...             ...        ...\n",
      "53568       12098  2020-03-29  post_per_month        6.0\n",
      "53569       12099  2020-03-22  post_per_month       20.0\n",
      "53570       12099  2020-03-29  post_per_month       49.0\n",
      "53571       12100  2020-03-22  post_per_month      114.0\n",
      "53572       12100  2020-03-29  post_per_month      282.0\n",
      "\n",
      "[53573 rows x 4 columns]\n",
      "SELECT metric.account_id,\n",
      "       DATE(metric.metric_time) AS metric_time,\n",
      "       metric_name.metric_name,\n",
      "       metric.metric_value AS end_value\n",
      "FROM metric\n",
      "JOIN metric_name ON metric_name.metric_name_id = metric.metric_name_id\n",
      "WHERE metric.metric_time BETWEEN '2020-01-01' AND '2020-05-10'\n",
      "  AND metric_name.metric_name = 'post_per_month'\n",
      "ORDER BY metric.account_id,\n",
      "         metric.metric_time\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_timespot(fieldname, metricname, d_start, d_end):\n",
    "    qr=session.query(\n",
    "        Metric.account_id,\n",
    "        func.DATE(Metric.metric_time).label(\"metric_time\"),\n",
    "        MetricName.metric_name,\n",
    "        Metric.metric_value.label(fieldname),\n",
    "        )\\\n",
    "    .join(MetricName, MetricName.metric_name_id==Metric.metric_name_id)\\\n",
    "    .filter(Metric.metric_time.between(d_start, d_end))\\\n",
    "    .filter(MetricName.metric_name==metricname)\\\n",
    "    .order_by(Metric.account_id, Metric.metric_time)\n",
    "    return qr\n",
    "\n",
    "q_relative=make_timespot(\"end_value\", \"post_per_month\", '2020-01-01', '2020-05-10')\n",
    "total_metric=pd.read_sql(q_relative.statement, engine)\n",
    "print(total_metric)\n",
    "\n",
    "print(pretty_sql(engine, q_relative))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continuous increments better than discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the discrete inc/dec result:99.00000000000001\n",
      "the log-inc/dec result:100.0\n",
      "the the contionuous rate:0.10517091807564771\n",
      "given the discrete rate of 0.1 the continuous rate is:0.09531017980432493\n"
     ]
    }
   ],
   "source": [
    "from math import log, exp\n",
    "\n",
    "# the discrete rate is set to 10%\n",
    "the_rate=0.1 \n",
    "\n",
    "# the problem of dicrete increment calculation\n",
    "some_value=100\n",
    "# 10% increase\n",
    "some_value*=1+the_rate\n",
    "# 10% decrease\n",
    "some_value*=1-the_rate\n",
    "\n",
    "# if we increase by 10% and decrease by 10% we should end up with the starting level, but...\n",
    "print(f\"the discrete inc/dec result:{some_value}\")\n",
    "\n",
    "# same calculation with natural logarithmics (ln)\n",
    "some_value=100\n",
    "# 10% increase\n",
    "some_value*=exp(the_rate)\n",
    "# 10% increase\n",
    "some_value*=exp(-the_rate)\n",
    "\n",
    "# that's better!\n",
    "print(f\"the log-inc/dec result:{some_value}\")\n",
    "\n",
    "#convert the continues rate (log) to a discrete value (normally annual)\n",
    "print(f\"the the contionuous rate:{exp(the_rate)-1}\")\n",
    "\n",
    "#calculate with 10% discrete to a continuous rate\n",
    "print(f\"given the discrete rate of {the_rate} the continuous rate is:{log(1+the_rate)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conversion of different time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time series:[100 120  90 130 100]\n",
      "the absolute diffs:[ 20 -30  40 -30]\n",
      "discrete relative increments:[ 0.2        -0.25        0.44444444 -0.23076923]\n",
      "continuous relative increments:[ 0.18232156 -0.28768207  0.36772478 -0.26236426]\n",
      "sum of discrete relative increments:0.16367521367521365\n",
      "sum of continuous relative increments:0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "# array of weekly spot values\n",
    "values=np.array([100,120,90,130,100])\n",
    "print(f\"the time series:{values}\")\n",
    "diffs=np.diff(values) #absolute diffs\n",
    "print(f\"the absolute diffs:{diffs}\")\n",
    "\n",
    "# we calcualte the discrete relative increments\n",
    "incs=(diffs/values[:-1])\n",
    "# the discrete increments\n",
    "print(f\"discrete relative increments:{incs}\")\n",
    "\n",
    "incs_ln=np.diff(np.log(values))\n",
    "print(f\"continuous relative increments:{incs_ln}\")\n",
    "\n",
    "\n",
    "# we started with 100 and ended with 100 but the sum if increments is not zero\n",
    "print(f\"sum of discrete relative increments:{np.sum(incs)}\")\n",
    "# ...whilst in the continuous case, it is\n",
    "print(f\"sum of continuous relative increments:{np.sum(incs_ln)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using the continuous increments of a time series\n",
    "The 4 weeks increment should be calculated over the mean of the 1-week (or daily) increments and then scaled (multiply by 4/multiply by 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id          metric_name   time_prev        time  spot_prev  \\\n",
      "0               1  newfriend_per_month  2020-03-01  2020-03-08        1.0   \n",
      "1               1  newfriend_per_month  2020-03-08  2020-03-15        1.0   \n",
      "2               1  newfriend_per_month  2020-03-15  2020-03-22        1.0   \n",
      "3               1  newfriend_per_month  2020-03-22  2020-03-29        2.0   \n",
      "4               2  newfriend_per_month  2020-03-01  2020-03-08        8.0   \n",
      "...           ...                  ...         ...         ...        ...   \n",
      "37556       12095  newfriend_per_month  2020-03-15  2020-03-22        7.0   \n",
      "37557       12095  newfriend_per_month  2020-03-22  2020-03-29       14.0   \n",
      "37558       12097  newfriend_per_month  2020-03-22  2020-03-29        2.0   \n",
      "37559       12099  newfriend_per_month  2020-03-22  2020-03-29        9.0   \n",
      "37560       12100  newfriend_per_month  2020-03-22  2020-03-29        6.0   \n",
      "\n",
      "       spot  lnx_prev       lnx   lnx_inc  \n",
      "0       1.0  0.000000  0.000000  0.000000  \n",
      "1       1.0  0.000000  0.000000  0.000000  \n",
      "2       2.0  0.000000  0.693147  0.693147  \n",
      "3       1.0  0.693147  0.000000 -0.693147  \n",
      "4       8.0  2.079442  2.079442  0.000000  \n",
      "...     ...       ...       ...       ...  \n",
      "37556  14.0  1.945910  2.639057  0.693147  \n",
      "37557  24.0  2.639057  3.178054  0.538997  \n",
      "37558   2.0  0.693147  0.693147  0.000000  \n",
      "37559  13.0  2.197225  2.564949  0.367725  \n",
      "37560  19.0  1.791759  2.944439  1.152680  \n",
      "\n",
      "[37561 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import and_, case, func, or_\n",
    "from sqlalchemy.orm import aliased\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def casecheck(thefield, label):\n",
    "    res=case([\n",
    "            (and_(thefield != None, thefield >0), \n",
    "            func.LOG(thefield)),\n",
    "        ], else_=0).label(label)\n",
    "    return res\n",
    "\n",
    "def casecheck_delta(thefield, thefield_prev, label):\n",
    "    res=case([\n",
    "            (and_(thefield != None, thefield >0,\n",
    "                 thefield_prev != None, thefield_prev >0), \n",
    "            func.LOG(thefield)-func.LOG(thefield_prev)),\n",
    "            (and_(or_(thefield == None, thefield <0),\n",
    "                 thefield_prev != None, thefield_prev >0), \n",
    "            -func.LOG(thefield_prev)),\n",
    "            (and_(or_(thefield_prev == None, thefield_prev <0),\n",
    "                 thefield != None, thefield >0), \n",
    "            0), # func.LOG(thefield)),\n",
    "        ], else_=0).label(label)\n",
    "    return res\n",
    "\n",
    "def metric_percentage(metricname):\n",
    "    MetricPrev=aliased(Metric)\n",
    "    ddelta=7\n",
    "    subq=session.query(\n",
    "            Metric.account_id,\n",
    "            MetricName.metric_name,\n",
    "            func.DATE(MetricPrev.metric_time).label(\"time_prev\"),\n",
    "            func.DATE(Metric.metric_time).label(\"time\"),\n",
    "            MetricPrev.metric_value.label(\"spot_prev\"),\n",
    "            Metric.metric_value.label(\"spot\"),\n",
    "            casecheck(MetricPrev.metric_value, \"lnx_prev\"),\n",
    "            casecheck(Metric.metric_value, \"lnx\"),\n",
    "            casecheck_delta(Metric.metric_value, MetricPrev.metric_value, \"lnx_inc\")\n",
    "        )\\\n",
    "        .join(MetricName, MetricName.metric_name_id==Metric.metric_name_id)\\\n",
    "        .join(MetricPrev, and_(\n",
    "              MetricPrev.account_id==Metric.account_id,\n",
    "              MetricPrev.metric_name_id==Metric.metric_name_id,\n",
    "              func.DATE(MetricPrev.metric_time)==func.DATE(to_days((Metric.metric_time))-ddelta)\n",
    "             ), isouter=True)\n",
    "    # ordering\n",
    "    subq=subq.order_by(Metric.account_id, MetricName.metric_name, Metric.metric_time)\n",
    "    # we should skip all start value of the series (per account_id and metric) given their is no real increment\n",
    "    subq=subq.filter(MetricPrev.metric_time != None) \n",
    "    # filtering to only one metric:\n",
    "    subq=subq.filter(MetricName.metric_name==metricname)\n",
    "    return subq\n",
    "\n",
    "subq=metric_percentage(\"newfriend_per_month\")\n",
    "#print(pretty_sql(subq))\n",
    "df=pd.read_sql(subq.statement, engine)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new metric_name_id=17 for newfriend_pcnt_chng\n",
      "       account_id          metric_name   time_prev        time  spot_prev  \\\n",
      "0               1  newfriend_per_month  2020-03-01  2020-03-08        1.0   \n",
      "1               1  newfriend_per_month  2020-03-08  2020-03-15        1.0   \n",
      "2               1  newfriend_per_month  2020-03-15  2020-03-22        1.0   \n",
      "3               1  newfriend_per_month  2020-03-22  2020-03-29        2.0   \n",
      "4               2  newfriend_per_month  2020-03-01  2020-03-08        8.0   \n",
      "...           ...                  ...         ...         ...        ...   \n",
      "37556       12095  newfriend_per_month  2020-03-15  2020-03-22        7.0   \n",
      "37557       12095  newfriend_per_month  2020-03-22  2020-03-29       14.0   \n",
      "37558       12097  newfriend_per_month  2020-03-22  2020-03-29        2.0   \n",
      "37559       12099  newfriend_per_month  2020-03-22  2020-03-29        9.0   \n",
      "37560       12100  newfriend_per_month  2020-03-22  2020-03-29        6.0   \n",
      "\n",
      "       spot  lnx_prev       lnx   lnx_inc  \n",
      "0       1.0  0.000000  0.000000  0.000000  \n",
      "1       1.0  0.000000  0.000000  0.000000  \n",
      "2       2.0  0.000000  0.693147  0.693147  \n",
      "3       1.0  0.693147  0.000000 -0.693147  \n",
      "4       8.0  2.079442  2.079442  0.000000  \n",
      "...     ...       ...       ...       ...  \n",
      "37556  14.0  1.945910  2.639057  0.693147  \n",
      "37557  24.0  2.639057  3.178054  0.538997  \n",
      "37558   2.0  0.693147  0.693147  0.000000  \n",
      "37559  13.0  2.197225  2.564949  0.367725  \n",
      "37560  19.0  1.791759  2.944439  1.152680  \n",
      "\n",
      "[37561 rows x 9 columns]\n",
      "new metric_name_id=16 for dislike_pcnt\n",
      "       account_id        metric_name   time_prev        time  spot_prev  spot  \\\n",
      "0               1  dislike_per_month  2020-03-01  2020-03-08        2.0   2.0   \n",
      "1               1  dislike_per_month  2020-03-08  2020-03-15        2.0   2.0   \n",
      "2               1  dislike_per_month  2020-03-15  2020-03-22        2.0   2.0   \n",
      "3               1  dislike_per_month  2020-03-22  2020-03-29        2.0   1.0   \n",
      "4               2  dislike_per_month  2020-03-01  2020-03-08        3.0   3.0   \n",
      "...           ...                ...         ...         ...        ...   ...   \n",
      "40361       12095  dislike_per_month  2020-03-15  2020-03-22        2.0   5.0   \n",
      "40362       12095  dislike_per_month  2020-03-22  2020-03-29        5.0   7.0   \n",
      "40363       12096  dislike_per_month  2020-03-22  2020-03-29        1.0   5.0   \n",
      "40364       12099  dislike_per_month  2020-03-22  2020-03-29        4.0   7.0   \n",
      "40365       12100  dislike_per_month  2020-03-22  2020-03-29        2.0   3.0   \n",
      "\n",
      "       lnx_prev       lnx   lnx_inc  \n",
      "0      0.693147  0.693147  0.000000  \n",
      "1      0.693147  0.693147  0.000000  \n",
      "2      0.693147  0.693147  0.000000  \n",
      "3      0.693147  0.000000 -0.693147  \n",
      "4      1.098612  1.098612  0.000000  \n",
      "...         ...       ...       ...  \n",
      "40361  0.693147  1.609438  0.916291  \n",
      "40362  1.609438  1.945910  0.336472  \n",
      "40363  0.000000  1.609438  1.609438  \n",
      "40364  1.386294  1.945910  0.559616  \n",
      "40365  0.693147  1.098612  0.405465  \n",
      "\n",
      "[40366 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select, literal\n",
    "\n",
    "metricname_base=\"newfriend_per_month\"\n",
    "newmetricname=\"newfriend_pcnt_chng\"\n",
    "\n",
    "todo={\n",
    "     \"newfriend_pcnt_chng\":\"newfriend_per_month\",\n",
    "     \"dislike_pcnt\":\"dislike_per_month\",\n",
    "}\n",
    "\n",
    "for newmetricname, metricname_base in todo.items():\n",
    "\n",
    "    metric_name_id=-1\n",
    "    metric_name_lu=session.query(MetricName.metric_name_id)\\\n",
    "        .filter(MetricName.metric_name == newmetricname).first() #or 0\n",
    "    if metric_name_lu is not None:\n",
    "        metric_name_lu = metric_name_lu[0]\n",
    "        metric_name_id = metric_name_lu\n",
    "        print(f\"new metric_name_id={metric_name_id} for {newmetricname}\")\n",
    "        qr=metric_percentage(metricname_base)\n",
    "        #print(pretty_sql(qr))\n",
    "        ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "        print(ddf)\n",
    "\n",
    "        if metric_name_id>0:\n",
    "            # delete all old values \"new_metric_id\"\n",
    "            session.commit()\n",
    "            old_metrics=session.query(Metric).filter(Metric.metric_name_id==metric_name_id).filter(Metric.metric_name_id==-1)\n",
    "            old_metrics.delete()\n",
    "            session.commit()\n",
    "\n",
    "            new_metrics_insert=qr.cte(\"new_metrics_insert\")\n",
    "            select_stm=select([\n",
    "                new_metrics_insert.c.account_id, \n",
    "                new_metrics_insert.c.time, \n",
    "                literal(metric_name_id).label(\"metric_name_id\"), #new_metrics_insert.c.metric_name_id, \n",
    "                new_metrics_insert.c.lnx_inc\n",
    "            ])\n",
    "            target_columns=['account_id', 'metric_time', 'metric_name_id', 'metric_value']\n",
    "            session.execute(Metric.__table__.insert().from_select(target_columns, select_stm))\n",
    "            session.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fat tail scores (§7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the functions below can be imported from curnmodels.statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def transform_skew_columns(data,skew_col_names):\n",
    "    for col in skew_col_names:\n",
    "        if col in data.columns:\n",
    "            data[col] = np.log(1.0+data[col])\n",
    "\n",
    "def transform_fattail_columns(data,fattail_col_names):\n",
    "    for col in fattail_col_names:\n",
    "        if col in data.columns:\n",
    "            data[col] = np.log(data[col] + np.sqrt(np.power(data[col],2) + 1.0))\n",
    "\n",
    "\n",
    "def fat_tail_scores(churn_data, stats, skew_thresh=4.0,**kwargs):\n",
    "\n",
    "    data_scores = churn_data.copy()\n",
    "    if \"is_churn\" in data_scores.columns:\n",
    "        data_scores.drop('is_churn',inplace=True,axis=1)\n",
    "\n",
    "    #stat_path = data_set_path.replace('.csv', '_summarystats.csv')\n",
    "    #assert os.path.isfile(stat_path),'You must running listing 5.2 first to generate stats'\n",
    "    #stats = pd.read_csv(stat_path,index_col=0)\n",
    "    if \"is_churn\" in stats.columns:\n",
    "        stats.drop('is_churn',inplace=True)\n",
    "\n",
    "    skewed_columns=(stats['skew']>skew_thresh) & (stats['min'] >= 0)\n",
    "    transform_skew_columns(data_scores,skewed_columns[skewed_columns].keys())\n",
    "\n",
    "    fattail_columns=(stats['skew']>skew_thresh) & (stats['min'] < 0)\n",
    "    transform_fattail_columns(data_scores,fattail_columns[fattail_columns].keys())\n",
    "\n",
    "    mean_vals = data_scores.mean()\n",
    "    std_vals = data_scores.std()\n",
    "    data_scores=(data_scores-mean_vals)/std_vals\n",
    "\n",
    "    if \"is_churn\" in churn_data.columns:\n",
    "        data_scores['is_churn']=churn_data['is_churn']\n",
    "\n",
    "    param_df = pd.DataFrame({'skew_score': skewed_columns,\n",
    "                             'fattail_score': fattail_columns,\n",
    "                             'mean': mean_vals,\n",
    "                             'std': std_vals})\n",
    "    return param_df, data_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     skew_score  fattail_score       mean  \\\n",
      "account_tenure                            False          False  44.140608   \n",
      "adview_per_month                           True          False   2.444507   \n",
      "adview_per_post                            True          False   1.300263   \n",
      "days_since_newfriend                       True          False   0.139360   \n",
      "dislike_pcnt                              False          False   0.081421   \n",
      "dislike_per_month                          True          False   1.843871   \n",
      "is_churn                                   True          False        NaN   \n",
      "like_per_month                             True          False   3.044163   \n",
      "like_per_post                              True          False   1.809296   \n",
      "message_per_month                          True          False   2.523749   \n",
      "newfriend_pcnt_chng                       False          False   0.055029   \n",
      "newfriend_per_month                        True          False   1.365929   \n",
      "post_per_message                           True          False   1.436285   \n",
      "post_per_month                             True          False   2.495774   \n",
      "reply_per_message                         False          False   1.317292   \n",
      "reply_per_month                            True          False   1.745592   \n",
      "unfriend_28day_avg_84day_obs              False          False   0.298653   \n",
      "unfriend_28day_avg_84day_obs_scaled       False          False   0.761468   \n",
      "unfriend_per_month                        False          False   0.726753   \n",
      "unfriend_per_newfriend                    False          False   0.830232   \n",
      "unfriend_per_newfriend_scaled             False          False   0.219105   \n",
      "\n",
      "                                           std  \n",
      "account_tenure                       26.489109  \n",
      "adview_per_month                      1.601925  \n",
      "adview_per_post                       0.976963  \n",
      "days_since_newfriend                  0.622392  \n",
      "dislike_pcnt                          0.774773  \n",
      "dislike_per_month                     1.291473  \n",
      "is_churn                                   NaN  \n",
      "like_per_month                        1.877960  \n",
      "like_per_post                         1.234749  \n",
      "message_per_month                     1.733860  \n",
      "newfriend_pcnt_chng                   0.874351  \n",
      "newfriend_per_month                   1.028600  \n",
      "post_per_message                      1.385550  \n",
      "post_per_month                        1.608499  \n",
      "reply_per_message                     1.511245  \n",
      "reply_per_month                       1.495488  \n",
      "unfriend_28day_avg_84day_obs          0.801173  \n",
      "unfriend_28day_avg_84day_obs_scaled   0.779677  \n",
      "unfriend_per_month                    0.934354  \n",
      "unfriend_per_newfriend                1.732766  \n",
      "unfriend_per_newfriend_scaled         0.397408  \n",
      "                             post_per_month  newfriend_per_month  \\\n",
      "account_id observation_date                                        \n",
      "16         2020-03-01             -0.185607            -0.654075   \n",
      "24         2020-03-01              0.424172             0.808182   \n",
      "118        2020-03-01              0.089079             0.019800   \n",
      "144        2020-03-01              0.950935             1.367549   \n",
      "157        2020-03-01             -1.551617            -1.327950   \n",
      "...                                     ...                  ...   \n",
      "13181      2020-05-10             -1.551617            -1.327950   \n",
      "13205      2020-05-10             -1.551617            -1.327950   \n",
      "13217      2020-05-10             -1.551617            -1.327950   \n",
      "13280      2020-05-10             -1.551617            -1.327950   \n",
      "13310      2020-05-10             -1.551617            -1.327950   \n",
      "\n",
      "                             like_per_month  adview_per_month  \\\n",
      "account_id observation_date                                     \n",
      "16         2020-03-01              0.272202         -0.521291   \n",
      "24         2020-03-01              0.343307          0.075186   \n",
      "118        2020-03-01             -0.344133         -0.227892   \n",
      "144        2020-03-01              0.369287          0.617682   \n",
      "157        2020-03-01             -1.251899         -1.525981   \n",
      "...                                     ...               ...   \n",
      "13181      2020-05-10             -1.620995         -1.525981   \n",
      "13205      2020-05-10             -1.620995         -1.525981   \n",
      "13217      2020-05-10             -1.620995         -1.525981   \n",
      "13280      2020-05-10             -1.620995         -1.525981   \n",
      "13310      2020-05-10             -1.620995         -1.525981   \n",
      "\n",
      "                             dislike_per_month  unfriend_per_month  \\\n",
      "account_id observation_date                                          \n",
      "16         2020-03-01                -0.040350           -0.777813   \n",
      "24         2020-03-01                -1.427727           -0.777813   \n",
      "118        2020-03-01                 0.719115           -0.777813   \n",
      "144        2020-03-01                 0.891897            0.292445   \n",
      "157        2020-03-01                -0.891016            1.362703   \n",
      "...                                        ...                 ...   \n",
      "13181      2020-05-10                -1.427727           -0.777813   \n",
      "13205      2020-05-10                -1.427727           -0.777813   \n",
      "13217      2020-05-10                -1.427727           -0.777813   \n",
      "13280      2020-05-10                -1.427727           -0.777813   \n",
      "13310      2020-05-10                -1.427727           -0.777813   \n",
      "\n",
      "                             message_per_month  reply_per_month  \\\n",
      "account_id observation_date                                       \n",
      "16         2020-03-01                 0.543289         0.835942   \n",
      "24         2020-03-01                 0.143518        -0.703747   \n",
      "118        2020-03-01                -0.821945        -1.167239   \n",
      "144        2020-03-01                -0.072586         0.436181   \n",
      "157        2020-03-01                 1.010991         0.929398   \n",
      "...                                        ...              ...   \n",
      "13181      2020-05-10                -1.455567        -1.167239   \n",
      "13205      2020-05-10                -1.455567        -1.167239   \n",
      "13217      2020-05-10                -1.455567        -1.167239   \n",
      "13280      2020-05-10                -1.455567        -1.167239   \n",
      "13310      2020-05-10                -1.455567        -1.167239   \n",
      "\n",
      "                             account_tenure  adview_per_post  ...  \\\n",
      "account_id observation_date                                   ...   \n",
      "16         2020-03-01              0.183449        -0.206405  ...   \n",
      "24         2020-03-01              0.183449        -0.177158  ...   \n",
      "118        2020-03-01              0.183449        -0.155216  ...   \n",
      "144        2020-03-01              0.183449        -0.146177  ...   \n",
      "157        2020-03-01              0.183449        -1.330923  ...   \n",
      "...                                     ...              ...  ...   \n",
      "13181      2020-05-10             -1.666368        -1.330923  ...   \n",
      "13205      2020-05-10             -1.666368        -1.330923  ...   \n",
      "13217      2020-05-10             -1.666368        -1.330923  ...   \n",
      "13280      2020-05-10             -1.666368        -1.330923  ...   \n",
      "13310      2020-05-10             -1.666368        -1.330923  ...   \n",
      "\n",
      "                             like_per_post  post_per_message  \\\n",
      "account_id observation_date                                    \n",
      "16         2020-03-01             0.875543         -0.524801   \n",
      "24         2020-03-01             0.196474          0.381432   \n",
      "118        2020-03-01            -0.327154          1.342104   \n",
      "144        2020-03-01            -0.346270          1.226379   \n",
      "157        2020-03-01            -1.465314         -1.036617   \n",
      "...                                    ...               ...   \n",
      "13181      2020-05-10            -1.465314         -1.036617   \n",
      "13205      2020-05-10            -1.465314         -1.036617   \n",
      "13217      2020-05-10            -1.465314         -1.036617   \n",
      "13280      2020-05-10            -1.465314         -1.036617   \n",
      "13310      2020-05-10            -1.465314         -1.036617   \n",
      "\n",
      "                             unfriend_per_newfriend  \\\n",
      "account_id observation_date                           \n",
      "16         2020-03-01                     -0.479137   \n",
      "24         2020-03-01                     -0.479137   \n",
      "118        2020-03-01                     -0.479137   \n",
      "144        2020-03-01                     -0.325240   \n",
      "157        2020-03-01                     -0.479137   \n",
      "...                                             ...   \n",
      "13181      2020-05-10                     -0.479137   \n",
      "13205      2020-05-10                     -0.479137   \n",
      "13217      2020-05-10                     -0.479137   \n",
      "13280      2020-05-10                     -0.479137   \n",
      "13310      2020-05-10                     -0.479137   \n",
      "\n",
      "                             unfriend_per_newfriend_scaled  dislike_pcnt  \\\n",
      "account_id observation_date                                                \n",
      "16         2020-03-01                            -0.551334      -0.10509   \n",
      "24         2020-03-01                            -0.371598      -0.10509   \n",
      "118        2020-03-01                            -0.072038      -0.10509   \n",
      "144        2020-03-01                            -0.359616      -0.10509   \n",
      "157        2020-03-01                            -0.551334      -0.10509   \n",
      "...                                                    ...           ...   \n",
      "13181      2020-05-10                            -0.551334      -0.10509   \n",
      "13205      2020-05-10                            -0.551334      -0.10509   \n",
      "13217      2020-05-10                            -0.551334      -0.10509   \n",
      "13280      2020-05-10                            -0.551334      -0.10509   \n",
      "13310      2020-05-10                            -0.551334      -0.10509   \n",
      "\n",
      "                             newfriend_pcnt_chng  \\\n",
      "account_id observation_date                        \n",
      "16         2020-03-01                  -0.062937   \n",
      "24         2020-03-01                  -0.062937   \n",
      "118        2020-03-01                  -0.062937   \n",
      "144        2020-03-01                  -0.062937   \n",
      "157        2020-03-01                  -0.062937   \n",
      "...                                          ...   \n",
      "13181      2020-05-10                  -0.062937   \n",
      "13205      2020-05-10                  -0.062937   \n",
      "13217      2020-05-10                  -0.062937   \n",
      "13280      2020-05-10                  -0.062937   \n",
      "13310      2020-05-10                  -0.062937   \n",
      "\n",
      "                             unfriend_28day_avg_84day_obs  \\\n",
      "account_id observation_date                                 \n",
      "16         2020-03-01                           -0.372769   \n",
      "24         2020-03-01                           -0.372769   \n",
      "118        2020-03-01                           -0.372769   \n",
      "144        2020-03-01                           -0.372769   \n",
      "157        2020-03-01                           -0.372769   \n",
      "...                                                   ...   \n",
      "13181      2020-05-10                           -0.372769   \n",
      "13205      2020-05-10                            0.459344   \n",
      "13217      2020-05-10                            0.459344   \n",
      "13280      2020-05-10                           -0.372769   \n",
      "13310      2020-05-10                            0.459344   \n",
      "\n",
      "                             unfriend_28day_avg_84day_obs_scaled  \\\n",
      "account_id observation_date                                        \n",
      "16         2020-03-01                                  -0.976646   \n",
      "24         2020-03-01                                  -0.243742   \n",
      "118        2020-03-01                                  -0.243742   \n",
      "144        2020-03-01                                   0.489163   \n",
      "157        2020-03-01                                   0.489163   \n",
      "...                                                          ...   \n",
      "13181      2020-05-10                                  -0.976646   \n",
      "13205      2020-05-10                                  -0.976646   \n",
      "13217      2020-05-10                                  -0.976646   \n",
      "13280      2020-05-10                                  -0.976646   \n",
      "13310      2020-05-10                                  -0.976646   \n",
      "\n",
      "                             days_since_newfriend  is_churn  \n",
      "account_id observation_date                                  \n",
      "16         2020-03-01                   -0.223910       0.0  \n",
      "24         2020-03-01                   -0.223910       0.0  \n",
      "118        2020-03-01                   -0.223910       0.0  \n",
      "144        2020-03-01                   -0.223910       0.0  \n",
      "157        2020-03-01                   -0.223910       0.0  \n",
      "...                                           ...       ...  \n",
      "13181      2020-05-10                    5.293495       0.0  \n",
      "13205      2020-05-10                   -0.223910       0.0  \n",
      "13217      2020-05-10                    2.654919       0.0  \n",
      "13280      2020-05-10                   -0.223910       0.0  \n",
      "13310      2020-05-10                   -0.223910       0.0  \n",
      "\n",
      "[15561 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from churnmodels.statistics import metric_scores, dataset_stats, fat_tail_scores\n",
    "dataset=dbhelper.get_dataset(d_obs_start, d_obs_end, metric_period)\n",
    "stats=dataset_stats(dataset)\n",
    "scores=metric_scores(dataset, stats)\n",
    "param_df, data_scores=fat_tail_scores(dataset, stats)\n",
    "print(param_df)\n",
    "print(data_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since event (§7.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id metric_date   last_date  days_since_event\n",
      "0               1  2020-05-03  2020-05-03               0.0\n",
      "1               1  2020-05-10  2020-05-10               0.0\n",
      "2               2  2020-05-03  2020-03-13              51.0\n",
      "3               2  2020-05-10  2020-03-13              58.0\n",
      "4               3  2020-05-03  2020-02-09              84.0\n",
      "...           ...         ...         ...               ...\n",
      "26973       14629  2020-05-10  2020-05-10               0.0\n",
      "26974       14630  2020-05-10  2020-05-10               0.0\n",
      "26975       14633  2020-05-10  2020-05-10               0.0\n",
      "26976       14638  2020-05-03  2020-05-03               0.0\n",
      "26977       14638  2020-05-10  2020-05-10               0.0\n",
      "\n",
      "[26978 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func\n",
    "step=7\n",
    "d1='2020-05-03'\n",
    "d2='2020-05-10'\n",
    "date_vals=dbhelper.days_interval(func.Date(to_days(d1)), func.Date(to_days(d2)), step=step, label=\"metric_date\").cte(\"date_vals\")\n",
    "\n",
    "def query_days_since_newfriend(ev_type=\"like\"):\n",
    "    last_event=session.query(\n",
    "        Event.account_id,\n",
    "        date_vals.c.metric_date,\n",
    "        func.max(func.DATE(Event.event_time)).label(\"last_date\")\n",
    "        )\\\n",
    "        .join(date_vals, func.DATE(Event.event_time)<=date_vals.c.metric_date)\\\n",
    "        .join(EventType, Event.event_type_id==EventType.event_type_id)\\\n",
    "        .filter(EventType.event_type_name==ev_type)\\\n",
    "        .group_by(Event.account_id, date_vals.c.metric_date)\\\n",
    "        .order_by(Event.account_id, date_vals.c.metric_date)\\\n",
    "        .cte(\"last_event\")\n",
    "\n",
    "    q1=session.query(\n",
    "        last_event.c.account_id,\n",
    "        last_event.c.metric_date,\n",
    "        last_event.c.last_date,\n",
    "        (to_days(last_event.c.metric_date) - to_days(last_event.c.last_date) ).label(\"days_since_event\"),\n",
    "        )\n",
    "    return q1\n",
    "\n",
    "q1= query_days_since_newfriend(\"like\")\n",
    "df=pd.read_sql(q1.statement, engine)\n",
    "#print(pretty_sql(q1))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new metric_name_id=20 for days_since_newfriend\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import literal, select\n",
    "\n",
    "newmetricname=\"days_since_newfriend\"\n",
    "\n",
    "metric_name_id=-1\n",
    "metric_name_lu=session.query(MetricName.metric_name_id)\\\n",
    "    .filter(MetricName.metric_name == newmetricname).first() #or 0\n",
    "if metric_name_lu is not None:\n",
    "    metric_name_lu = metric_name_lu[0]\n",
    "    metric_name_id = metric_name_lu\n",
    "    print(f\"new metric_name_id={metric_name_id} for {newmetricname}\")\n",
    "    qr= query_days_since_newfriend(\"like\")\n",
    "    #print(pretty_sql(qr))\n",
    "    #ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "    #print(ddf)\n",
    "\n",
    "    if metric_name_id>0:\n",
    "        # delete all old values \"new_metric_id\"\n",
    "        session.commit()\n",
    "        old_metrics=session.query(Metric).filter(Metric.metric_name_id==metric_name_id).filter(Metric.metric_name_id==-1)\n",
    "        old_metrics.delete()\n",
    "        session.commit()\n",
    "\n",
    "        new_metrics_insert=qr.cte(\"new_metrics_insert\")\n",
    "        select_stm=select([\n",
    "            new_metrics_insert.c.account_id, \n",
    "            new_metrics_insert.c.metric_date, \n",
    "            literal(metric_name_id).label(\"metric_name_id\"), #new_metrics_insert.c.metric_name_id, \n",
    "            new_metrics_insert.c.days_since_event\n",
    "        ])\n",
    "        target_columns=['account_id', 'metric_time', 'metric_name_id', 'metric_value']\n",
    "        session.execute(Metric.__table__.insert().from_select(target_columns, select_stm))\n",
    "        session.commit()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Events (§7.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id metric_date  total_count         n\n",
      "0               1  2020-05-03            1  0.333333\n",
      "1               1  2020-05-10            1  0.333333\n",
      "2               2  2020-05-03            2  0.666667\n",
      "3               2  2020-05-10            2  0.666667\n",
      "4               4  2020-05-03            4  1.333333\n",
      "...           ...         ...          ...       ...\n",
      "22037       14582  2020-05-10            1  0.333333\n",
      "22038       14605  2020-05-10            1  0.333333\n",
      "22039       14609  2020-05-10            1  0.333333\n",
      "22040       14629  2020-05-10            1  0.333333\n",
      "22041       14638  2020-05-10            1  0.333333\n",
      "\n",
      "[22042 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func, and_, cast, Float, literal\n",
    "step=7\n",
    "frac=28.0/84.0\n",
    "d1='2020-05-03'\n",
    "d2='2020-05-10'\n",
    "date_vals=dbhelper.days_interval(func.Date(to_days(d1)), func.Date(to_days(d2)), step=step, label=\"metric_date\").cte(\"date_vals\")\n",
    "\n",
    "def query_scaling_number(ev_type=None):\n",
    "    last_event=session.query(\n",
    "        Event.account_id,\n",
    "        date_vals.c.metric_date,\n",
    "        func.count().label(\"total_count\"),\n",
    "        (cast(func.count(),Float)*frac).label(\"n\")\n",
    "        )\\\n",
    "        .join(date_vals, literal(True))\\\n",
    "        .join(EventType, Event.event_type_id==EventType.event_type_id)\\\n",
    "        .filter(EventType.event_type_name==ev_type)\\\n",
    "        .filter(and_( Event.event_time <=date_vals.c.metric_date,\n",
    "                   Event.event_time >func.DATE(to_days(date_vals.c.metric_date) -84)))\\\n",
    "        .group_by(Event.account_id, date_vals.c.metric_date)\\\n",
    "        .order_by(Event.account_id, date_vals.c.metric_date)\\\n",
    "        .cte(\"last_event\")\n",
    "\n",
    "    q1=session.query(\n",
    "        last_event.c.account_id,\n",
    "        last_event.c.metric_date,\n",
    "        last_event.c.total_count,\n",
    "        last_event.c.n,\n",
    "        )\n",
    "    return q1\n",
    "\n",
    "q1= query_scaling_number(\"unfriend\")\n",
    "df=pd.read_sql(q1.statement, engine)\n",
    "#print(pretty_sql(q1))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new metric_name_id=18 for unfriend_28day_avg_84day_obs\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import literal, select\n",
    "\n",
    "newmetricname=\"unfriend_28day_avg_84day_obs\"\n",
    "\n",
    "metric_name_id=-1\n",
    "metric_name_lu=session.query(MetricName.metric_name_id)\\\n",
    "    .filter(MetricName.metric_name == newmetricname).first() #or 0\n",
    "if metric_name_lu is not None:\n",
    "    metric_name_lu = metric_name_lu[0]\n",
    "    metric_name_id = metric_name_lu\n",
    "    print(f\"new metric_name_id={metric_name_id} for {newmetricname}\")\n",
    "    qr= query_scaling_number(\"unfriend\")\n",
    "    #print(pretty_sql(qr))\n",
    "    #ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "    #print(ddf)\n",
    "\n",
    "    if metric_name_id>0:\n",
    "        # delete all old values \"new_metric_id\"\n",
    "        session.commit()\n",
    "        old_metrics=session.query(Metric).filter(Metric.metric_name_id==metric_name_id).filter(Metric.metric_name_id==-1)\n",
    "        old_metrics.delete()\n",
    "        session.commit()\n",
    "\n",
    "        new_metrics_insert=qr.cte(\"new_metrics_insert\")\n",
    "        select_stm=select([\n",
    "            new_metrics_insert.c.account_id, \n",
    "            new_metrics_insert.c.metric_date, \n",
    "            literal(metric_name_id).label(\"metric_name_id\"), #new_metrics_insert.c.metric_name_id, \n",
    "            new_metrics_insert.c.n\n",
    "        ])\n",
    "        target_columns=['account_id', 'metric_time', 'metric_name_id', 'metric_value']\n",
    "        session.execute(Metric.__table__.insert().from_select(target_columns, select_stm))\n",
    "        session.commit()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenure Scaled Events per month (§7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account_id metric_date  tenure_metric  count_unscaled   scaling  \\\n",
      "0               2  2020-03-01           46.0               2  0.608696   \n",
      "1               2  2020-03-08           53.0               2  0.528302   \n",
      "2               4  2020-03-01           47.0               4  0.595745   \n",
      "3               4  2020-03-08           54.0               4  0.518519   \n",
      "4               4  2020-03-15           61.0               4  0.459016   \n",
      "...           ...         ...            ...             ...       ...   \n",
      "40175       12088  2020-03-29           22.0               1  1.272727   \n",
      "40176       12092  2020-03-29           20.0               1  1.400000   \n",
      "40177       12093  2020-03-22           19.0               1  1.473684   \n",
      "40178       12093  2020-03-29           26.0               3  1.076923   \n",
      "40179       12095  2020-03-29           21.0               1  1.333333   \n",
      "\n",
      "       message_permonth_84day_scaled  \n",
      "0                           1.217391  \n",
      "1                           1.056604  \n",
      "2                           2.382979  \n",
      "3                           2.074074  \n",
      "4                           1.836066  \n",
      "...                              ...  \n",
      "40175                       1.272727  \n",
      "40176                       1.400000  \n",
      "40177                       1.473684  \n",
      "40178                       3.230769  \n",
      "40179                       1.333333  \n",
      "\n",
      "[40180 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func, and_, cast, Float, literal\n",
    "step=7\n",
    "frac=28.0/84.0\n",
    "d1='2020-05-03'\n",
    "d2='2020-05-10'\n",
    "date_vals=dbhelper.days_interval(func.Date(to_days(d1)), func.Date(to_days(d2)), step=step, label=\"metric_date\").cte(\"date_vals\")\n",
    "\n",
    "def get_least(a,b):\n",
    "    return case([\n",
    "        (a<=b, a)\n",
    "        ],\n",
    "        else_=b)\n",
    "def query_scaling_number_tenure(ev_type=None, me_name=None):\n",
    "    \n",
    "    last_event=session.query(\n",
    "        Metric.account_id,\n",
    "        func.DATE(Metric.metric_time).label(\"metric_date\"),\n",
    "        Metric.metric_value.label(\"tenure_metric\"),\n",
    "        func.count().label(\"count_unscaled\"),\n",
    "        (28.0/ get_least(Metric.metric_value, 84.0)).label(\"scaling\"),\n",
    "        ((28.0/ get_least(Metric.metric_value, 84.0))*func.count()).label(\"message_permonth_84day_scaled\"),\n",
    "        )\\\n",
    "        .join(Event, and_(\n",
    "              Event.account_id==Metric.account_id,\n",
    "              Event.event_time<=Metric.metric_time,\n",
    "              func.DATE(Event.event_time)>func.DATE(to_days(Metric.metric_time) -84),\n",
    "             ))\\\n",
    "        .join(EventType, Event.event_type_id==EventType.event_type_id)\\\n",
    "        .join(MetricName, Metric.metric_name_id==MetricName.metric_name_id)\\\n",
    "        .filter(EventType.event_type_name==ev_type)\\\n",
    "        .filter(MetricName.metric_name==me_name)\\\n",
    "        .filter(Metric.metric_value>14)\\\n",
    "        .group_by(Metric.account_id, Metric.metric_time, Metric.metric_value)\\\n",
    "        .order_by(Metric.account_id, Metric.metric_time, Metric.metric_value)\\\n",
    "        .cte(\"last_event\")\n",
    "\n",
    "    q1=session.query(\n",
    "        last_event.c.account_id,\n",
    "        last_event.c.metric_date,\n",
    "        last_event.c.tenure_metric,\n",
    "        last_event.c.count_unscaled,\n",
    "        last_event.c.scaling,\n",
    "        last_event.c.message_permonth_84day_scaled,\n",
    "        )\n",
    "    return q1\n",
    "\n",
    "q1= query_scaling_number_tenure(\"unfriend\", \"account_tenure\")\n",
    "df=pd.read_sql(q1.statement, engine)\n",
    "#print(pretty_sql(q1))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new metric_name_id=19 for unfriend_28day_avg_84day_obs_scaled\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import literal, select\n",
    "\n",
    "newmetricname=\"unfriend_28day_avg_84day_obs_scaled\"\n",
    "\n",
    "metric_name_id=-1\n",
    "metric_name_lu=session.query(MetricName.metric_name_id)\\\n",
    "    .filter(MetricName.metric_name == newmetricname).first() #or 0\n",
    "if metric_name_lu is not None:\n",
    "    metric_name_lu = metric_name_lu[0]\n",
    "    metric_name_id = metric_name_lu\n",
    "    print(f\"new metric_name_id={metric_name_id} for {newmetricname}\")\n",
    "    qr= query_scaling_number_tenure(\"unfriend\", \"account_tenure\")\n",
    "    #print(pretty_sql(qr))\n",
    "    #ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "    #print(ddf)\n",
    "\n",
    "    if metric_name_id>0:\n",
    "        # delete all old values \"new_metric_id\"\n",
    "        session.commit()\n",
    "        old_metrics=session.query(Metric).filter(Metric.metric_name_id==metric_name_id).filter(Metric.metric_name_id==-1)\n",
    "        old_metrics.delete()\n",
    "        session.commit()\n",
    "\n",
    "        new_metrics_insert=qr.cte(\"new_metrics_insert\")\n",
    "        select_stm=select([\n",
    "            new_metrics_insert.c.account_id, \n",
    "            new_metrics_insert.c.metric_date, \n",
    "            literal(metric_name_id).label(\"metric_name_id\"), #new_metrics_insert.c.metric_name_id, \n",
    "            new_metrics_insert.c.message_permonth_84day_scaled\n",
    "        ])\n",
    "        target_columns=['account_id', 'metric_time', 'metric_name_id', 'metric_value']\n",
    "        session.execute(Metric.__table__.insert().from_select(target_columns, select_stm))\n",
    "        session.commit()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new metric_name_id=15 for unfriend_per_newfriend_scaled\n",
      "       account_id metric_time  metric_name_id  metric_value  metric_value_log\n",
      "0               2  2020-03-01              -1      0.152174         -1.882731\n",
      "1               2  2020-03-08              -1      0.132075         -2.024382\n",
      "2               4  2020-03-01              -1      0.476596         -0.741087\n",
      "3               4  2020-03-08              -1      0.345679         -1.062245\n",
      "4               4  2020-03-15              -1      0.306011         -1.184134\n",
      "...           ...         ...             ...           ...               ...\n",
      "40175       12088  2020-03-29              -1      0.181818         -1.704748\n",
      "40176       12092  2020-03-29              -1      1.400000          0.336472\n",
      "40177       12093  2020-03-22              -1      0.491228         -0.710847\n",
      "40178       12093  2020-03-29              -1      0.461538         -0.773190\n",
      "40179       12095  2020-03-29              -1      0.055556         -2.890372\n",
      "\n",
      "[40180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select, literal\n",
    "todo={\n",
    "    \"unfriend_per_newfriend_scaled\":[\"unfriend_28day_avg_84day_obs_scaled\", \"newfriend_per_month\"],\n",
    "}\n",
    "\n",
    "for newmetricname, pairs in todo.items():\n",
    "    metric_name_id=-1\n",
    "    metric_name_lu=session.query(MetricName.metric_name_id)\\\n",
    "        .filter(MetricName.metric_name == newmetricname).first() #or 0\n",
    "    if metric_name_lu is not None:\n",
    "        metric_name_lu = metric_name_lu[0]\n",
    "        metric_name_id = metric_name_lu\n",
    "    print(f\"new metric_name_id={metric_name_id} for {newmetricname}\")\n",
    "    #num_metric=make_relative_metrics_part(d_obs_start, d_obs_end, \"num_metric\", \"num_value\", pairs[0])\n",
    "    #den_metric=make_relative_metrics_part(d_obs_start, d_obs_end, \"den_metric\", \"den_value\", pairs[1])\n",
    "    #qr=qr=make_relative_metrics_sub(num_metric, den_metric, metric_name_id)\n",
    "    qr=dbhelper.make_relative_metrics(d_obs_start, d_obs_end, pairs[0], pairs[1])\n",
    "    #print(pretty_sql(qr))\n",
    "    ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "    print(ddf)\n",
    "    \n",
    "    if metric_name_id>0:\n",
    "        # delete all old values \"new_metric_id\"\n",
    "        session.commit()\n",
    "        old_metrics=session.query(Metric).filter(Metric.metric_name_id==metric_name_id).filter(Metric.metric_name_id==-1)\n",
    "        old_metrics.delete()\n",
    "        session.commit()\n",
    "        \n",
    "        new_metrics_insert=qr.cte(\"new_metrics_insert\")\n",
    "        select_stm=select([\n",
    "            new_metrics_insert.c.account_id, \n",
    "            func.DATE(new_metrics_insert.c.metric_time).label(\"metric_time\"), \n",
    "            literal(metric_name_id).label(\"metric_name_id\"), #new_metrics_insert.c.metric_name_id, \n",
    "            new_metrics_insert.c.metric_value\n",
    "        ])\n",
    "        target_columns=['account_id', 'metric_time', 'metric_name_id', 'metric_value']\n",
    "        session.execute(Metric.__table__.insert().from_select(target_columns, select_stm))\n",
    "        session.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count active users (§7.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH RECURSIVE cnt(metric_date) AS\n",
      "  (SELECT DATE(Date(julianday('2020-05-03'))) AS metric_date\n",
      "   UNION ALL SELECT DATE(julianday(cnt.metric_date) + 7) AS metric_date\n",
      "   FROM cnt\n",
      "   WHERE DATE(julianday(cnt.metric_date) + 7) <= Date(julianday('2020-05-10'))),\n",
      "               date_vals AS\n",
      "  (SELECT cnt.metric_date AS metric_date\n",
      "   FROM cnt)\n",
      "SELECT event.account_id,\n",
      "       date_vals.metric_date,\n",
      "       count(DISTINCT event.account_id) AS n_distinct_users\n",
      "FROM event\n",
      "JOIN date_vals ON 1\n",
      "WHERE DATE(event.event_time) <= date_vals.metric_date\n",
      "  AND DATE(event.event_time) > DATE(julianday(date_vals.metric_date) - 84)\n",
      "GROUP BY event.account_id,\n",
      "         date_vals.metric_date\n",
      "ORDER BY event.account_id,\n",
      "         date_vals.metric_date\n",
      "       account_id metric_date  n_distinct_users\n",
      "0               1  2020-05-03                 1\n",
      "1               1  2020-05-10                 1\n",
      "2               2  2020-05-03                 1\n",
      "3               2  2020-05-10                 1\n",
      "4               4  2020-05-03                 1\n",
      "...           ...         ...               ...\n",
      "26439       14629  2020-05-10                 1\n",
      "26440       14630  2020-05-10                 1\n",
      "26441       14633  2020-05-10                 1\n",
      "26442       14638  2020-05-03                 1\n",
      "26443       14638  2020-05-10                 1\n",
      "\n",
      "[26444 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "with date_vals AS (\n",
    "     select i::timestamp as metric_date\n",
    "     from generate_series('%from_yyyy-mm-dd', '%to_yyyy-mm-dd', '7 day'::interval) i\n",
    ")\n",
    "select account_id, metric_date, count(distinct user_id) as n_distinct_users\n",
    "from event e inner join date_vals d\n",
    "on e.event_time <= metric_date\n",
    "and e.event_time > metric_date - interval '%obs_period days'\n",
    "group by account_id, metric_date\n",
    "order by metric_date, account_id;\n",
    "\"\"\"\n",
    "from sqlalchemy import select, literal, distinct\n",
    "step=7\n",
    "obs_period=84\n",
    "d1='2020-05-03'\n",
    "d2='2020-05-10'\n",
    "date_vals=dbhelper.days_interval(func.Date(to_days(d1)), func.Date(to_days(d2)), step=step, label=\"metric_date\").cte(\"date_vals\")\n",
    "\n",
    "qr = session.query(\n",
    "    Event.account_id, \n",
    "    date_vals.c.metric_date, \n",
    "    func.count(distinct(Event.account_id)).label(\"n_distinct_users\")\n",
    "    )\\\n",
    "    .join(date_vals, literal(True))\\\n",
    "    .filter(func.DATE(Event.event_time) <= date_vals.c.metric_date)\\\n",
    "    .filter(func.DATE(Event.event_time) > func.DATE(to_days(date_vals.c.metric_date)-obs_period))\\\n",
    "    .group_by(Event.account_id, date_vals.c.metric_date)\\\n",
    "    .order_by(Event.account_id, date_vals.c.metric_date)\\\n",
    "\n",
    "print(pretty_sql(engine, qr))\n",
    "ddf=pd.read_sql(qr.statement, dbhelper.engine)\n",
    "print(ddf)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
